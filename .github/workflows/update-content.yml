name: Hourly Content Aggregation

on:
  schedule:
    - cron: '0 * * * *'   # æ¯å°æ—¶ï¼ˆUTCï¼‰
  workflow_dispatch:

# ä¸åŒåˆ†æ”¯çš„å¹¶å‘äº’ä¸å½±å“ï¼›åŒä¸€åˆ†æ”¯ä»…ä¿ç•™æœ€æ–°ä¸€æ¬¡è¿è¡Œ
concurrency:
  group: aggregator-${{ github.repository }}-${{ github.ref_name }}
  cancel-in-progress: true

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      # å›ºå®š Python ç‰ˆæœ¬ï¼Œä¿è¯ wheel å‘½ä¸­ä¸ä¾èµ–ç¨³å®š
      PY_VERSION: "3.12"
      # NLTK æ•°æ®ç¼“å­˜ç›®å½•ï¼ˆæ”¾åœ¨ workspaceï¼Œé¿å… runner.temp è§£æé—®é¢˜ï¼‰
      NLTK_DATA: ${{ github.workspace }}/.nltk_data
      # â€”â€” å¯é€‰æ€§èƒ½å¼€å…³ï¼ˆaggregator.py å·²æ”¯æŒï¼‰â€”â€”
      ENABLE_FULLTEXT: "1"           # 1=æŠ“å…¨æ–‡, 0=åªç”¨RSSæ‘˜è¦
      MAX_FULLTEXT_PER_RUN: "40"     # æ¯æ¬¡æœ€å¤šæŠ“å¤šå°‘æ¡å…¨æ–‡ï¼›0=ä¸é™åˆ¶ï¼ˆä¸æ—§è¡Œä¸ºä¸€è‡´ï¼‰
      ENABLE_TIMING_LOGS: "1"        # æ‰“å°é˜¶æ®µè€—æ—¶
      SUMMARIZE_CONCURRENCY: "4"     # å¹¶å‘æ‘˜è¦æ•°é‡

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          # å¦‚æœä½ å¸Œæœ›å§‹ç»ˆåœ¨ main è·‘æ‰åŠ ä¸‹é¢è¿™è¡Œï¼›å¦åˆ™ä¿æŒæ³¨é‡Šå³å¯åœ¨å½“å‰åˆ†æ”¯è¿è¡Œ
          # ref: main

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PY_VERSION }}
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'

      # âœ… ç¼“å­˜ï¼šæŠ“å…¨æ–‡/æ‘˜è¦çš„æœ¬åœ°æ•°æ®åº“ + NLTK è¯åº“
      - name: Restore aggregator & NLTK cache
        uses: actions/cache@v4
        with:
          path: |
            .cache/aggregator
            summary_cache.json
            ${{ env.NLTK_DATA }}
          key: agg-nlp-${{ runner.os }}-${{ env.PY_VERSION }}-${{ hashFiles('feeds.json') }}
          restore-keys: |
            agg-nlp-${{ runner.os }}-${{ env.PY_VERSION }}-

      - name: Install deps
        run: |
          pip install -r requirements.txt

      - name: Ensure NLTK punkt (cached)
        shell: bash
        run: |
          python - << 'PY'
          import os, nltk
          nltk.data.path.insert(0, os.environ.get("NLTK_DATA",""))
          try:
              nltk.data.find("tokenizers/punkt")
              print("[nltk] punkt found in cache")
          except LookupError:
              print("[nltk] downloading punkt ...")
              nltk.download("punkt", download_dir=os.environ.get("NLTK_DATA",""))
          PY

      - name: Run aggregator
        run: |
          set -e
          python scripts/aggregator.py

      - name: Generate sitemap
        run: |
          python scripts/generate_sitemap.py

      # âœ… æäº¤äº§ç‰©ï¼›æ¨å›æœ¬æ¬¡è¿è¡Œæ‰€åœ¨åˆ†æ”¯ï¼›ç¼“å­˜ç”± actions/cache æŒä¹…åŒ–
      - name: Commit & push (safe retry to current branch)
        env:
          BRANCH_NAME: ${{ github.ref_name }}   # è‡ªåŠ¨ç­‰äºå½“å‰åˆ†æ”¯å
        run: |
          set -e
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          git add posts/ sitemap.xml
          git commit -m "ğŸ¤– Auto-update content and sitemap" || { echo "Nothing to commit"; exit 0; }

          # å…ˆæ¨åˆ°å½“å‰åˆ†æ”¯ï¼›å¤±è´¥åˆ™åŸºäºè¯¥åˆ†æ”¯ rebase åé‡è¯•ï¼ˆä¸è§¦ç¢° mainï¼‰
          git push origin HEAD:refs/heads/$BRANCH_NAME || {
            echo "Push failed; rebase on latest $BRANCH_NAME then retry..."
            git fetch origin $BRANCH_NAME
            git rebase origin/$BRANCH_NAME
            git push origin HEAD:refs/heads/$BRANCH_NAME
          }
